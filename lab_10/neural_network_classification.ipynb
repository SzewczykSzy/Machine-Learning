{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Szymon Szewczyk\n",
    "# Naural Network Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import layers\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set, test_set = mnist.load_data()\n",
    "\n",
    "X_train, y_train = training_set\n",
    "X_test, y_test = test_set\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float64)/255.0\n",
    "X_test = X_test.astype(np.float64)/255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "batch_size = 128\n",
    "epochs = 30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "\n",
    "    keras.Input(shape=input_shape),\n",
    "    keras.layers.Flatten(),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.7523 - accuracy: 0.8140 - val_loss: 0.4095 - val_accuracy: 0.8953\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3897 - accuracy: 0.8970 - val_loss: 0.3349 - val_accuracy: 0.9095\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.9074 - val_loss: 0.3075 - val_accuracy: 0.9156\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3145 - accuracy: 0.9131 - val_loss: 0.2944 - val_accuracy: 0.9175\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3001 - accuracy: 0.9171 - val_loss: 0.2840 - val_accuracy: 0.9222\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2907 - accuracy: 0.9189 - val_loss: 0.2786 - val_accuracy: 0.9233\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2834 - accuracy: 0.9212 - val_loss: 0.2741 - val_accuracy: 0.9250\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2781 - accuracy: 0.9219 - val_loss: 0.2719 - val_accuracy: 0.9257\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2733 - accuracy: 0.9235 - val_loss: 0.2685 - val_accuracy: 0.9262\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2702 - accuracy: 0.9244 - val_loss: 0.2674 - val_accuracy: 0.9260\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2672 - accuracy: 0.9248 - val_loss: 0.2655 - val_accuracy: 0.9279\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2639 - accuracy: 0.9264 - val_loss: 0.2638 - val_accuracy: 0.9286\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2617 - accuracy: 0.9270 - val_loss: 0.2620 - val_accuracy: 0.9296\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2593 - accuracy: 0.9274 - val_loss: 0.2625 - val_accuracy: 0.9274\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2578 - accuracy: 0.9282 - val_loss: 0.2606 - val_accuracy: 0.9289\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2558 - accuracy: 0.9287 - val_loss: 0.2618 - val_accuracy: 0.9296\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2544 - accuracy: 0.9292 - val_loss: 0.2600 - val_accuracy: 0.9292\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2530 - accuracy: 0.9293 - val_loss: 0.2591 - val_accuracy: 0.9294\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2518 - accuracy: 0.9299 - val_loss: 0.2592 - val_accuracy: 0.9308\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2507 - accuracy: 0.9300 - val_loss: 0.2627 - val_accuracy: 0.9287\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2494 - accuracy: 0.9307 - val_loss: 0.2604 - val_accuracy: 0.9295\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2483 - accuracy: 0.9310 - val_loss: 0.2584 - val_accuracy: 0.9314\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2472 - accuracy: 0.9310 - val_loss: 0.2598 - val_accuracy: 0.9303\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2462 - accuracy: 0.9313 - val_loss: 0.2607 - val_accuracy: 0.9293\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2456 - accuracy: 0.9319 - val_loss: 0.2599 - val_accuracy: 0.9298\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2446 - accuracy: 0.9316 - val_loss: 0.2595 - val_accuracy: 0.9308\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2437 - accuracy: 0.9322 - val_loss: 0.2582 - val_accuracy: 0.9308\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2430 - accuracy: 0.9327 - val_loss: 0.2592 - val_accuracy: 0.9317\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2421 - accuracy: 0.9327 - val_loss: 0.2604 - val_accuracy: 0.9298\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2414 - accuracy: 0.9329 - val_loss: 0.2595 - val_accuracy: 0.9306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x212c9284ee0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"linear.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_probab = model.predict(X_test)\n",
    "y_pred = np.argmax(y_probab, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       980\n",
      "           1       0.97      0.98      0.98      1135\n",
      "           2       0.92      0.91      0.91      1032\n",
      "           3       0.90      0.91      0.91      1010\n",
      "           4       0.93      0.93      0.93       982\n",
      "           5       0.92      0.86      0.89       892\n",
      "           6       0.95      0.95      0.95       958\n",
      "           7       0.93      0.92      0.93      1028\n",
      "           8       0.88      0.90      0.89       974\n",
      "           9       0.92      0.91      0.91      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "[[ 965    0    1    2    0    5    4    2    1    0]\n",
      " [   0 1113    3    3    0    1    3    2   10    0]\n",
      " [   4    9  938   13    6    3   11    8   37    3]\n",
      " [   3    0   23  920    0   23    2   12   21    6]\n",
      " [   1    1    8    1  914    0   12    4   10   31]\n",
      " [   9    2    7   39    9  768   13    9   31    5]\n",
      " [  13    3    9    1    7   11  911    1    2    0]\n",
      " [   1    6   23    7    8    1    0  948    2   32]\n",
      " [   7    6   10   19    9   21    8   11  876    7]\n",
      " [  11    7    1   13   27    5    0   20    5  920]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_8 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,850\n",
      "Trainable params: 59,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            keras.layers.Flatten(),\n",
    "            layers.Dense(64, activation=\"tanh\"),\n",
    "            layers.Dense(128, activation=\"tanh\"),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4034 - accuracy: 0.8874 - val_loss: 0.2252 - val_accuracy: 0.9360\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9428 - val_loss: 0.1697 - val_accuracy: 0.9502\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1424 - accuracy: 0.9586 - val_loss: 0.1422 - val_accuracy: 0.9578\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9676 - val_loss: 0.1178 - val_accuracy: 0.9660\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0891 - accuracy: 0.9735 - val_loss: 0.1214 - val_accuracy: 0.9639\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0731 - accuracy: 0.9778 - val_loss: 0.1092 - val_accuracy: 0.9667\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0615 - accuracy: 0.9815 - val_loss: 0.1022 - val_accuracy: 0.9707\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0508 - accuracy: 0.9845 - val_loss: 0.1052 - val_accuracy: 0.9671\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0417 - accuracy: 0.9880 - val_loss: 0.1042 - val_accuracy: 0.9706\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0359 - accuracy: 0.9901 - val_loss: 0.1036 - val_accuracy: 0.9708\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.1045 - val_accuracy: 0.9705\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0255 - accuracy: 0.9927 - val_loss: 0.1076 - val_accuracy: 0.9703\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 0.1073 - val_accuracy: 0.9717\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9960 - val_loss: 0.1170 - val_accuracy: 0.9690\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0155 - accuracy: 0.9956 - val_loss: 0.1162 - val_accuracy: 0.9697\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9964 - val_loss: 0.1148 - val_accuracy: 0.9723\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.1201 - val_accuracy: 0.9703\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.1183 - val_accuracy: 0.9719\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.1221 - val_accuracy: 0.9707\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.1297 - val_accuracy: 0.9698\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.1301 - val_accuracy: 0.9707\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.1465 - val_accuracy: 0.9681\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.1281 - val_accuracy: 0.9711\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.1414 - val_accuracy: 0.9703\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.1411 - val_accuracy: 0.9710\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.1819 - val_accuracy: 0.9653\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.1552 - val_accuracy: 0.9697\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.1409 - val_accuracy: 0.9718\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.1438 - val_accuracy: 0.9715\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 7.6287e-04 - accuracy: 0.9999 - val_loss: 0.1355 - val_accuracy: 0.9728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x212c4cd1490>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mlp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.97      0.97      1032\n",
      "           3       0.97      0.98      0.97      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.99      0.97      0.98       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.97      0.97      0.97      1028\n",
      "           8       0.97      0.97      0.97       974\n",
      "           9       0.98      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "[[ 968    0    2    0    0    2    5    1    2    0]\n",
      " [   0 1124    2    2    0    0    2    1    4    0]\n",
      " [   5    1 1005    4    2    1    3    3    8    0]\n",
      " [   1    2    5  986    2    2    0    6    5    1]\n",
      " [   1    0    1    1  962    0    5    0    2   10]\n",
      " [   4    0    0    9    1  869    4    2    1    2]\n",
      " [   5    2    2    1    4    2  941    0    1    0]\n",
      " [   0    5   12    3    2    1    0  998    2    5]\n",
      " [   5    0    4    8    4    3    3    5  940    2]\n",
      " [   2    2    0    7    9    2    1    8    1  977]]\n"
     ]
    }
   ],
   "source": [
    "y_probab = model.predict(X_test)\n",
    "y_pred = np.argmax(y_probab, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "375/375 [==============================] - 25s 66ms/step - loss: 0.3852 - accuracy: 0.8835 - val_loss: 0.0970 - val_accuracy: 0.9737\n",
      "Epoch 2/30\n",
      "375/375 [==============================] - 25s 67ms/step - loss: 0.1116 - accuracy: 0.9658 - val_loss: 0.0676 - val_accuracy: 0.9804\n",
      "Epoch 3/30\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 0.0841 - accuracy: 0.9734 - val_loss: 0.0537 - val_accuracy: 0.9846\n",
      "Epoch 4/30\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 0.0715 - accuracy: 0.9777 - val_loss: 0.0494 - val_accuracy: 0.9858\n",
      "Epoch 5/30\n",
      "375/375 [==============================] - 25s 67ms/step - loss: 0.0610 - accuracy: 0.9809 - val_loss: 0.0439 - val_accuracy: 0.9874\n",
      "Epoch 6/30\n",
      "375/375 [==============================] - 27s 72ms/step - loss: 0.0555 - accuracy: 0.9827 - val_loss: 0.0448 - val_accuracy: 0.9872\n",
      "Epoch 7/30\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 0.0513 - accuracy: 0.9841 - val_loss: 0.0415 - val_accuracy: 0.9881\n",
      "Epoch 8/30\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 0.0485 - accuracy: 0.9845 - val_loss: 0.0393 - val_accuracy: 0.9884\n",
      "Epoch 9/30\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 0.0429 - accuracy: 0.9860 - val_loss: 0.0402 - val_accuracy: 0.9895\n",
      "Epoch 10/30\n",
      "375/375 [==============================] - 25s 66ms/step - loss: 0.0410 - accuracy: 0.9872 - val_loss: 0.0382 - val_accuracy: 0.9890\n",
      "Epoch 11/30\n",
      "375/375 [==============================] - 25s 66ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.0392 - val_accuracy: 0.9883\n",
      "Epoch 12/30\n",
      "375/375 [==============================] - 25s 65ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.0332 - val_accuracy: 0.9904\n",
      "Epoch 13/30\n",
      "375/375 [==============================] - 26s 69ms/step - loss: 0.0346 - accuracy: 0.9886 - val_loss: 0.0336 - val_accuracy: 0.9904\n",
      "Epoch 14/30\n",
      "375/375 [==============================] - 27s 73ms/step - loss: 0.0350 - accuracy: 0.9890 - val_loss: 0.0349 - val_accuracy: 0.9908\n",
      "Epoch 15/30\n",
      "375/375 [==============================] - 28s 75ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0323 - val_accuracy: 0.9906\n",
      "Epoch 16/30\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 0.0303 - accuracy: 0.9898 - val_loss: 0.0323 - val_accuracy: 0.9915\n",
      "Epoch 17/30\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 0.0301 - accuracy: 0.9899 - val_loss: 0.0323 - val_accuracy: 0.9912\n",
      "Epoch 18/30\n",
      "375/375 [==============================] - 24s 65ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.0319 - val_accuracy: 0.9904\n",
      "Epoch 19/30\n",
      "375/375 [==============================] - 23s 61ms/step - loss: 0.0274 - accuracy: 0.9913 - val_loss: 0.0323 - val_accuracy: 0.9906\n",
      "Epoch 20/30\n",
      "375/375 [==============================] - 22s 60ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.0306 - val_accuracy: 0.9916\n",
      "Epoch 21/30\n",
      "375/375 [==============================] - 22s 58ms/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.0289 - val_accuracy: 0.9920\n",
      "Epoch 22/30\n",
      "375/375 [==============================] - 25s 66ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.0320 - val_accuracy: 0.9908\n",
      "Epoch 23/30\n",
      "375/375 [==============================] - 25s 67ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.0292 - val_accuracy: 0.9921\n",
      "Epoch 24/30\n",
      "375/375 [==============================] - 23s 60ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 0.0316 - val_accuracy: 0.9915\n",
      "Epoch 25/30\n",
      "375/375 [==============================] - 23s 63ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0289 - val_accuracy: 0.9918\n",
      "Epoch 26/30\n",
      "375/375 [==============================] - 23s 62ms/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.0282 - val_accuracy: 0.9918\n",
      "Epoch 27/30\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.0322 - val_accuracy: 0.9912\n",
      "Epoch 28/30\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0227 - accuracy: 0.9920 - val_loss: 0.0292 - val_accuracy: 0.9923\n",
      "Epoch 29/30\n",
      "375/375 [==============================] - 21s 56ms/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 0.0310 - val_accuracy: 0.9926\n",
      "Epoch 30/30\n",
      "375/375 [==============================] - 21s 57ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.0301 - val_accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x212c90d3fa0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"conv.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       980\n",
      "           1       1.00      1.00      1.00      1135\n",
      "           2       1.00      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      1.00      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       1.00      0.99      0.99       958\n",
      "           7       0.99      1.00      0.99      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.99      0.99      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "[[ 977    0    0    0    1    0    0    1    1    0]\n",
      " [   0 1133    2    0    0    0    0    0    0    0]\n",
      " [   1    0 1022    0    2    0    0    7    0    0]\n",
      " [   0    0    1 1004    0    2    0    2    1    0]\n",
      " [   0    0    0    0  980    0    1    0    0    1]\n",
      " [   0    0    0    4    0  884    1    1    1    1]\n",
      " [   1    2    1    0    2    2  948    0    2    0]\n",
      " [   0    2    0    1    0    0    0 1023    1    1]\n",
      " [   2    0    1    1    0    1    0    0  966    3]\n",
      " [   0    0    0    0    3    3    1    4    1  997]]\n"
     ]
    }
   ],
   "source": [
    "y_probab = model.predict(X_test)\n",
    "y_pred = np.argmax(y_probab, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
